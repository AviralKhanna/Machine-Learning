{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","collapsed_sections":["p-YwQol4jJVv","DZUZxN_FjMIt","tB5OJwC6j5dZ"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M_76YHaA-83i","executionInfo":{"status":"ok","timestamp":1705464510155,"user_tz":-330,"elapsed":19990,"user":{"displayName":"girish girish","userId":"16813817461950920468"}},"outputId":"0ecb3863-d096-4d78-bed9-8574aee3bc9c"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["DATA PATH"],"metadata":{"id":"p-YwQol4jJVv"}},{"cell_type":"code","source":["# Load the data\n","acoustic_data = pd.read_csv('/content/drive/MyDrive/Autistic/Autistic_Features/ACOUSTIC.csv')\n","paralinguistic_data = pd.read_csv('/content/drive/MyDrive/Autistic/Autistic_Features/Paralinguistic.csv')\n","linguistic_data = pd.read_csv('/content/drive/MyDrive/Autistic/Autistic_Features/Linguistic_features.csv')\n"],"metadata":{"id":"TexZCpXUzqOL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# fnn layers"],"metadata":{"id":"Fyo4EDN_gD9n"}},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report\n","from sklearn.preprocessing import StandardScaler\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import TensorDataset, DataLoader"],"metadata":{"id":"MHuDwMA_joTa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["DATA PROCESSING"],"metadata":{"id":"pTdtx6b3n3pF"}},{"cell_type":"code","source":["# loading the DATA\n","acoustic_data = pd.read_csv('/content/drive/MyDrive/Autistic/Autistic_Features/ACOUSTIC.csv')\n","paralinguistic_data = pd.read_csv('/content/drive/MyDrive/Autistic/Autistic_Features/Paralinguistic.csv')\n","linguistic_data = pd.read_csv('/content/drive/MyDrive/Autistic/Autistic_Features/Linguistic_features.csv')\n","\n","# Concatination features on the bases of 'name'\n","merged_data = acoustic_data.merge(paralinguistic_data, on='name').merge(linguistic_data, on='name')\n","\n","# DROP the unwanted columns\n","X = merged_data.drop(columns=['name', 'Class']).values\n","y = merged_data['Class'].values\n","\n","# Standardize and normalize the features\n","scaler = StandardScaler()\n","X = scaler.fit_transform(X)\n","\n","# Split data into training and testing\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=65, random_state=42)\n"],"metadata":{"id":"qqWHTn43jqUQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////"],"metadata":{"id":"TsmxQYebp_R6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class TransformerEncoder(nn.Module):\n","    def __init__(self, input_dim, num_heads, hidden_dim, num_layers, num_classes, ffnn_hidden_dim):\n","        super(TransformerEncoder, self).__init__()\n","        self.embedding = nn.Linear(input_dim, hidden_dim)\n","        encoder_layers = nn.TransformerEncoderLayer(d_model=hidden_dim, nhead=num_heads, batch_first=True)\n","        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers=num_layers)\n","\n","        # Feedforward layer\n","        self.ffnn = nn.Linear(hidden_dim, ffnn_hidden_dim)\n","        self.relu = nn.ReLU()\n","\n","        # Final classification layer\n","        self.fc = nn.Linear(ffnn_hidden_dim, num_classes)\n","\n","    def forward(self, src):\n","        src = self.embedding(src)\n","        out = self.transformer_encoder(src)\n","\n","        # Applying the feedforward layer\n","        out = self.ffnn(out)\n","        out = self.relu(out)\n","\n","        out = self.fc(out)\n","        return out\n"],"metadata":{"id":"yNAPEryyj0Ju"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////"],"metadata":{"id":"hd2D4Z_yqJLz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Ensure this matches the number of features in your input data\n","input_dim = X_train.shape[1]  # Update this based on your actual input features\n","\n","# hidden_dim\n","hidden_dim = 128\n","num_heads = 4\n","num_layers = 2\n","num_classes = len(set(y_train))  # TO Calculate the number of classes\n","ffnn_hidden_dim = 256  # adjust as of requirement\n","\n","model = TransformerEncoder(input_dim=input_dim, num_heads=num_heads, hidden_dim=hidden_dim, num_layers=num_layers, num_classes=num_classes, ffnn_hidden_dim=ffnn_hidden_dim)\n","\n","#Loss and Optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","# Convert to PyTorch tensors\n","X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n","X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n","y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n","y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n","\n","# Data Loader\n","train_data = TensorDataset(X_train_tensor, y_train_tensor)\n","train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n","test_data = TensorDataset(X_test_tensor, y_test_tensor)\n","test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n"],"metadata":{"id":"KA_UycUupywe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////"],"metadata":{"id":"bgylrCnRqK5J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Training Loop\n","num_epochs = 100\n","for epoch in range(num_epochs):\n","    model.train()\n","    total_loss = 0\n","    for inputs, labels in train_loader:\n","        optimizer.zero_grad()  # Zero the gradient buffers\n","        outputs = model(inputs)  # Forward pass\n","        loss = criterion(outputs, labels)  # Compute loss\n","        loss.backward()  # Backpropagation\n","        optimizer.step()  # Update weights\n","        total_loss += loss.item()\n","\n","    average_loss = total_loss / len(train_loader)\n","    print(f'Epoch {epoch+1}/{num_epochs}, Average Loss: {average_loss:.4f}')\n","\n","\n","# Evaluate the model on the test set\n","accuracy = evaluate_model(model, test_loader)\n","print(f'Accuracy on Test Data: {accuracy:.2f}%')\n","\n","# Calculate and print the classification report\n","true_labels = y_test  # True labels from the test set\n","predicted_labels = []\n","\n","model.eval()\n","with torch.no_grad():\n","    for inputs, labels in test_loader:\n","        outputs = model(inputs)\n","        _, predicted = torch.max(outputs.data, 1)\n","        predicted_labels.extend(predicted.cpu().numpy())\n","\n","classification_rep = classification_report(true_labels, predicted_labels)\n","print(\"Classification Report:\\n\", classification_rep)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Kd_ktkZugFV3","executionInfo":{"status":"ok","timestamp":1705434987896,"user_tz":-330,"elapsed":14585,"user":{"displayName":"girish girish","userId":"16813817461950920468"}},"outputId":"acb85007-7bf4-424f-d4ce-f6c9ed53377d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100, Average Loss: 0.2694\n","Epoch 2/100, Average Loss: 0.0318\n","Epoch 3/100, Average Loss: 0.0167\n","Epoch 4/100, Average Loss: 0.0948\n","Epoch 5/100, Average Loss: 0.0493\n","Epoch 6/100, Average Loss: 0.0243\n","Epoch 7/100, Average Loss: 0.0120\n","Epoch 8/100, Average Loss: 0.0027\n","Epoch 9/100, Average Loss: 0.0019\n","Epoch 10/100, Average Loss: 0.0016\n","Epoch 11/100, Average Loss: 0.0010\n","Epoch 12/100, Average Loss: 0.0006\n","Epoch 13/100, Average Loss: 0.0005\n","Epoch 14/100, Average Loss: 0.0004\n","Epoch 15/100, Average Loss: 0.0003\n","Epoch 16/100, Average Loss: 0.0003\n","Epoch 17/100, Average Loss: 0.0002\n","Epoch 18/100, Average Loss: 0.0002\n","Epoch 19/100, Average Loss: 0.0002\n","Epoch 20/100, Average Loss: 0.0007\n","Epoch 21/100, Average Loss: 0.0002\n","Epoch 22/100, Average Loss: 0.0003\n","Epoch 23/100, Average Loss: 0.0342\n","Epoch 24/100, Average Loss: 0.1461\n","Epoch 25/100, Average Loss: 0.2318\n","Epoch 26/100, Average Loss: 0.1560\n","Epoch 27/100, Average Loss: 0.0544\n","Epoch 28/100, Average Loss: 0.0769\n","Epoch 29/100, Average Loss: 0.0116\n","Epoch 30/100, Average Loss: 0.0306\n","Epoch 31/100, Average Loss: 0.0417\n","Epoch 32/100, Average Loss: 0.0024\n","Epoch 33/100, Average Loss: 0.0376\n","Epoch 34/100, Average Loss: 0.0201\n","Epoch 35/100, Average Loss: 0.0024\n","Epoch 36/100, Average Loss: 0.0025\n","Epoch 37/100, Average Loss: 0.0390\n","Epoch 38/100, Average Loss: 0.0036\n","Epoch 39/100, Average Loss: 0.0069\n","Epoch 40/100, Average Loss: 0.0980\n","Epoch 41/100, Average Loss: 0.0336\n","Epoch 42/100, Average Loss: 0.0067\n","Epoch 43/100, Average Loss: 0.0209\n","Epoch 44/100, Average Loss: 0.0025\n","Epoch 45/100, Average Loss: 0.0075\n","Epoch 46/100, Average Loss: 0.0009\n","Epoch 47/100, Average Loss: 0.0007\n","Epoch 48/100, Average Loss: 0.0006\n","Epoch 49/100, Average Loss: 0.0005\n","Epoch 50/100, Average Loss: 0.0004\n","Epoch 51/100, Average Loss: 0.0004\n","Epoch 52/100, Average Loss: 0.0003\n","Epoch 53/100, Average Loss: 0.0003\n","Epoch 54/100, Average Loss: 0.0003\n","Epoch 55/100, Average Loss: 0.0003\n","Epoch 56/100, Average Loss: 0.0003\n","Epoch 57/100, Average Loss: 0.0003\n","Epoch 58/100, Average Loss: 0.0002\n","Epoch 59/100, Average Loss: 0.0002\n","Epoch 60/100, Average Loss: 0.0002\n","Epoch 61/100, Average Loss: 0.0002\n","Epoch 62/100, Average Loss: 0.0002\n","Epoch 63/100, Average Loss: 0.0002\n","Epoch 64/100, Average Loss: 0.0002\n","Epoch 65/100, Average Loss: 0.0001\n","Epoch 66/100, Average Loss: 0.0001\n","Epoch 67/100, Average Loss: 0.0001\n","Epoch 68/100, Average Loss: 0.0001\n","Epoch 69/100, Average Loss: 0.0001\n","Epoch 70/100, Average Loss: 0.0001\n","Epoch 71/100, Average Loss: 0.0001\n","Epoch 72/100, Average Loss: 0.0001\n","Epoch 73/100, Average Loss: 0.0001\n","Epoch 74/100, Average Loss: 0.0001\n","Epoch 75/100, Average Loss: 0.0001\n","Epoch 76/100, Average Loss: 0.0001\n","Epoch 77/100, Average Loss: 0.0001\n","Epoch 78/100, Average Loss: 0.0001\n","Epoch 79/100, Average Loss: 0.0001\n","Epoch 80/100, Average Loss: 0.0001\n","Epoch 81/100, Average Loss: 0.0001\n","Epoch 82/100, Average Loss: 0.0001\n","Epoch 83/100, Average Loss: 0.0001\n","Epoch 84/100, Average Loss: 0.0001\n","Epoch 85/100, Average Loss: 0.0001\n","Epoch 86/100, Average Loss: 0.0001\n","Epoch 87/100, Average Loss: 0.0001\n","Epoch 88/100, Average Loss: 0.0001\n","Epoch 89/100, Average Loss: 0.0001\n","Epoch 90/100, Average Loss: 0.0001\n","Epoch 91/100, Average Loss: 0.0001\n","Epoch 92/100, Average Loss: 0.0001\n","Epoch 93/100, Average Loss: 0.0001\n","Epoch 94/100, Average Loss: 0.0000\n","Epoch 95/100, Average Loss: 0.0000\n","Epoch 96/100, Average Loss: 0.0000\n","Epoch 97/100, Average Loss: 0.0000\n","Epoch 98/100, Average Loss: 0.0000\n","Epoch 99/100, Average Loss: 0.0000\n","Epoch 100/100, Average Loss: 0.0000\n","Accuracy on Test Data: 98.46%\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","           0       1.00      0.95      0.98        22\n","           1       0.98      1.00      0.99        43\n","\n","    accuracy                           0.98        65\n","   macro avg       0.99      0.98      0.98        65\n","weighted avg       0.98      0.98      0.98        65\n","\n"]}]},{"cell_type":"code","source":["#////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////"],"metadata":{"id":"kf4oV_1jqM8d"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////"],"metadata":{"id":"DZUZxN_FjMIt"}},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import TensorDataset, DataLoader\n","# Load the data\n","acoustic_data = pd.read_csv('/content/drive/MyDrive/Autistic/Autistic_Features/ACOUSTIC.csv')\n","paralinguistic_data = pd.read_csv('/content/drive/MyDrive/Autistic/Autistic_Features/Paralinguistic.csv')\n","linguistic_data = pd.read_csv('/content/drive/MyDrive/Autistic/Autistic_Features/Linguistic_features.csv')\n","\n","for inputs, labels in train_loader:\n","    print(\"Batch input shape:\", inputs.shape)\n","    print(\"Batch labels shape:\", labels.shape)\n","    break\n","\n","# Concatination datasets on 'name'\n","merged_data = acoustic_data.merge(paralinguistic_data, on='name').merge(linguistic_data, on='name')\n","\n","# Preprocess data\n","X = merged_data.drop(columns=['name', 'Class']).values\n","y = merged_data['Class'].values\n","\n","# Standardize and normalize the features\n","scaler = StandardScaler()\n","X = scaler.fit_transform(X)\n","\n","# Split data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=45, random_state=42)\n","\n","class TransformerEncoder(nn.Module):# Defining transformer encoder\n","    def __init__(self, input_dim, num_heads, hidden_dim, num_layers, num_classes):\n","        super(TransformerEncoder, self).__init__()\n","        self.embedding = nn.Linear(input_dim, hidden_dim)\n","        encoder_layers = nn.TransformerEncoderLayer(d_model=hidden_dim, nhead=num_heads, batch_first=True)\n","        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers=num_layers)\n","\n","        # Initialize the final linear layer with num_classes\n","        self.fc = nn.Linear(hidden_dim, num_classes)\n","\n","    def forward(self, src):\n","        src = self.embedding(src)\n","        out = self.transformer_encoder(src)\n","        # No averaging, directly pass to final layer\n","        out = self.fc(out)\n","        return out\n","\n","\n","\n","\n","# Ensure this matches the number of features in your input data\n","input_dim = X_train.shape[1]  # Update this based on your actual input features\n","\n","# Update the hidden_dim if necessary\n","hidden_dim = 128  # This can be different but should align with your model architecture\n","num_heads = 4\n","num_layers = 2\n","num_classes = len(set(y_train))  # Calculate the number of classes\n","\n","model = TransformerEncoder(input_dim=input_dim, num_heads=num_heads, hidden_dim=hidden_dim, num_layers=num_layers, num_classes=num_classes)\n","\n","# Loss and Optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","# Convert to PyTorch tensors\n","X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n","X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n","y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n","y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n","\n","# Data Loader\n","train_data = TensorDataset(X_train_tensor, y_train_tensor)\n","train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n","test_data = TensorDataset(X_test_tensor, y_test_tensor)\n","test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n","\n","# Training Loop\n","num_epochs = 100\n","for epoch in range(num_epochs):\n","    model.train()\n","    total_loss = 0\n","    for inputs, labels in train_loader:\n","        optimizer.zero_grad()  # Zero the gradient buffers\n","        outputs = model(inputs)  # Forward pass\n","        loss = criterion(outputs, labels)  # Compute loss\n","        loss.backward()  # Backpropagation\n","        optimizer.step()  # Update weights\n","        total_loss += loss.item()\n","\n","    average_loss = total_loss / len(train_loader)\n","    print(f'Epoch {epoch+1}/{num_epochs}, Average Loss: {average_loss:.4f}')\n","\n","# Evaluation Function\n","def evaluate_model(model, test_loader):\n","    model.eval()\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for inputs, labels in test_loader:\n","            outputs = model(inputs)\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","    accuracy = 100 * correct / total\n","    return accuracy\n","\n","# Evaluate the model on the test set\n","accuracy = evaluate_model(model, test_loader)\n","print(f'Accuracy on Test Data: {accuracy:.2f}%')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"USMCuSHTJ07b","executionInfo":{"status":"ok","timestamp":1705428911177,"user_tz":-330,"elapsed":11441,"user":{"displayName":"girish girish","userId":"16813817461950920468"}},"outputId":"c5788612-86cc-4f60-c5e2-fab251fe419d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Batch input shape: torch.Size([32, 1800])\n","Batch labels shape: torch.Size([32])\n","Epoch 1/100, Average Loss: 0.2989\n","Epoch 2/100, Average Loss: 0.0263\n","Epoch 3/100, Average Loss: 0.0111\n","Epoch 4/100, Average Loss: 0.0034\n","Epoch 5/100, Average Loss: 0.0007\n","Epoch 6/100, Average Loss: 0.0004\n","Epoch 7/100, Average Loss: 0.1840\n","Epoch 8/100, Average Loss: 0.0641\n","Epoch 9/100, Average Loss: 0.1607\n","Epoch 10/100, Average Loss: 0.0494\n","Epoch 11/100, Average Loss: 0.0090\n","Epoch 12/100, Average Loss: 0.0133\n","Epoch 13/100, Average Loss: 0.0026\n","Epoch 14/100, Average Loss: 0.0022\n","Epoch 15/100, Average Loss: 0.0016\n","Epoch 16/100, Average Loss: 0.0014\n","Epoch 17/100, Average Loss: 0.0011\n","Epoch 18/100, Average Loss: 0.0008\n","Epoch 19/100, Average Loss: 0.0007\n","Epoch 20/100, Average Loss: 0.0008\n","Epoch 21/100, Average Loss: 0.0008\n","Epoch 22/100, Average Loss: 0.0005\n","Epoch 23/100, Average Loss: 0.0006\n","Epoch 24/100, Average Loss: 0.0004\n","Epoch 25/100, Average Loss: 0.0004\n","Epoch 26/100, Average Loss: 0.0004\n","Epoch 27/100, Average Loss: 0.0004\n","Epoch 28/100, Average Loss: 0.0004\n","Epoch 29/100, Average Loss: 0.0003\n","Epoch 30/100, Average Loss: 0.0003\n","Epoch 31/100, Average Loss: 0.0003\n","Epoch 32/100, Average Loss: 0.0003\n","Epoch 33/100, Average Loss: 0.0003\n","Epoch 34/100, Average Loss: 0.0003\n","Epoch 35/100, Average Loss: 0.0003\n","Epoch 36/100, Average Loss: 0.0003\n","Epoch 37/100, Average Loss: 0.0003\n","Epoch 38/100, Average Loss: 0.0002\n","Epoch 39/100, Average Loss: 0.0002\n","Epoch 40/100, Average Loss: 0.0002\n","Epoch 41/100, Average Loss: 0.0002\n","Epoch 42/100, Average Loss: 0.0002\n","Epoch 43/100, Average Loss: 0.0002\n","Epoch 44/100, Average Loss: 0.0002\n","Epoch 45/100, Average Loss: 0.0002\n","Epoch 46/100, Average Loss: 0.0002\n","Epoch 47/100, Average Loss: 0.0002\n","Epoch 48/100, Average Loss: 0.0002\n","Epoch 49/100, Average Loss: 0.0002\n","Epoch 50/100, Average Loss: 0.0002\n","Epoch 51/100, Average Loss: 0.0002\n","Epoch 52/100, Average Loss: 0.0002\n","Epoch 53/100, Average Loss: 0.0002\n","Epoch 54/100, Average Loss: 0.0002\n","Epoch 55/100, Average Loss: 0.0002\n","Epoch 56/100, Average Loss: 0.0001\n","Epoch 57/100, Average Loss: 0.0001\n","Epoch 58/100, Average Loss: 0.0001\n","Epoch 59/100, Average Loss: 0.0001\n","Epoch 60/100, Average Loss: 0.0001\n","Epoch 61/100, Average Loss: 0.0001\n","Epoch 62/100, Average Loss: 0.0001\n","Epoch 63/100, Average Loss: 0.0001\n","Epoch 64/100, Average Loss: 0.0001\n","Epoch 65/100, Average Loss: 0.0001\n","Epoch 66/100, Average Loss: 0.0001\n","Epoch 67/100, Average Loss: 0.0001\n","Epoch 68/100, Average Loss: 0.0001\n","Epoch 69/100, Average Loss: 0.0001\n","Epoch 70/100, Average Loss: 0.0001\n","Epoch 71/100, Average Loss: 0.0001\n","Epoch 72/100, Average Loss: 0.0001\n","Epoch 73/100, Average Loss: 0.0001\n","Epoch 74/100, Average Loss: 0.0001\n","Epoch 75/100, Average Loss: 0.0001\n","Epoch 76/100, Average Loss: 0.0001\n","Epoch 77/100, Average Loss: 0.0001\n","Epoch 78/100, Average Loss: 0.0001\n","Epoch 79/100, Average Loss: 0.0001\n","Epoch 80/100, Average Loss: 0.0001\n","Epoch 81/100, Average Loss: 0.0001\n","Epoch 82/100, Average Loss: 0.0001\n","Epoch 83/100, Average Loss: 0.0001\n","Epoch 84/100, Average Loss: 0.0001\n","Epoch 85/100, Average Loss: 0.0001\n","Epoch 86/100, Average Loss: 0.0001\n","Epoch 87/100, Average Loss: 0.0001\n","Epoch 88/100, Average Loss: 0.0001\n","Epoch 89/100, Average Loss: 0.0001\n","Epoch 90/100, Average Loss: 0.0001\n","Epoch 91/100, Average Loss: 0.0001\n","Epoch 92/100, Average Loss: 0.0001\n","Epoch 93/100, Average Loss: 0.0001\n","Epoch 94/100, Average Loss: 0.0001\n","Epoch 95/100, Average Loss: 0.0001\n","Epoch 96/100, Average Loss: 0.0001\n","Epoch 97/100, Average Loss: 0.0001\n","Epoch 98/100, Average Loss: 0.0001\n","Epoch 99/100, Average Loss: 0.0001\n","Epoch 100/100, Average Loss: 0.0001\n","Accuracy on Test Data: 97.78%\n"]}]},{"cell_type":"markdown","source":[],"metadata":{"id":"Dah3-utJjdD-"}},{"cell_type":"markdown","source":["# try to apply of encoder"],"metadata":{"id":"tB5OJwC6j5dZ"}},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import TensorDataset, DataLoader\n","# Load the data\n","acoustic_data = pd.read_csv('/content/drive/MyDrive/Autistic/Autistic_Features/ACOUSTIC.csv')\n","paralinguistic_data = pd.read_csv('/content/drive/MyDrive/Autistic/Autistic_Features/Paralinguistic.csv')\n","linguistic_data = pd.read_csv('/content/drive/MyDrive/Autistic/Autistic_Features/Linguistic_features.csv')\n","\n","for inputs, labels in train_loader:\n","    print(\"Batch input shape:\", inputs.shape)\n","    print(\"Batch labels shape:\", labels.shape)\n","    break\n","# Concatenation datasets on 'name'\n","merged_data = acoustic_data.merge(paralinguistic_data, on='name').merge(linguistic_data, on='name')\n","\n","# Preprocess data\n","X = merged_data.drop(columns=['name', 'Class']).values\n","y = merged_data['Class'].values\n","\n","# Standardize and normalize the features\n","scaler = StandardScaler()\n","X = scaler.fit_transform(X)\n","\n","# Split data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=65, random_state=0)\n","\n","# Indices for feature splits\n","acoustic_end = 768\n","paralinguistic_end = acoustic_end + 1024\n","\n","\n","class FeatureAttention(nn.Module):\n","    def __init__(self, feature_dim, attention_dim):\n","        super(FeatureAttention, self).__init__()\n","        self.attention_weight = nn.Linear(feature_dim, attention_dim)\n","        self.context_vector = nn.Linear(attention_dim, 1, bias=False)\n","\n","    def forward(self, x):\n","        attn = torch.tanh(self.attention_weight(x))\n","        score = self.context_vector(attn)\n","        attention_weights = torch.softmax(score, dim=1)\n","        return torch.sum(x * attention_weights, dim=1)\n","\n","class TransformerEncoder(nn.Module):\n","    def __init__(self, acoustic_dim, paralinguistic_dim, linguistic_dim, hidden_dim, num_classes, ffnn_hidden_dim):\n","        super(TransformerEncoder, self).__init__()\n","        self.acoustic_attention = FeatureAttention(acoustic_dim, hidden_dim)\n","        self.paralinguistic_attention = FeatureAttention(paralinguistic_dim, hidden_dim)\n","        self.linguistic_attention = FeatureAttention(linguistic_dim, hidden_dim)\n","\n","        self.embedding = nn.Linear(hidden_dim * 3, hidden_dim)  # x3 for concatenation of feature attentions\n","        encoder_layers = nn.TransformerEncoderLayer(d_model=hidden_dim, nhead=4, batch_first=True)\n","        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers=2)\n","\n","        self.ffnn = nn.Linear(hidden_dim, ffnn_hidden_dim)\n","        self.relu = nn.ReLU()\n","        self.fc = nn.Linear(ffnn_hidden_dim, num_classes)\n","\n","    def forward(self, acoustic_features, paralinguistic_features, linguistic_features):\n","        acoustic_context = self.acoustic_attention(acoustic_features)\n","        paralinguistic_context = self.paralinguistic_attention(paralinguistic_features)\n","        linguistic_context = self.linguistic_attention(linguistic_features)\n","\n","        # Combine the contexts\n","        combined_context = torch.cat((acoustic_context, paralinguistic_context, linguistic_context), dim=1)\n","        combined_context = self.embedding(combined_context)\n","        combined_context = self.transformer_encoder(combined_context.unsqueeze(1))\n","\n","        out = self.ffnn(combined_context.squeeze(1))\n","        out = self.relu(out)\n","        out = self.fc(out)\n","        return out\n","\n","# Model parameters\n","acoustic_dim = 768  # Number of acoustic features\n","paralinguistic_dim = 1024  # Number of paralinguistic features\n","linguistic_dim = 6  # Number of linguistic features\n","hidden_dim = 128\n","num_heads = 4\n","num_layers = 2\n","num_classes = len(set(y_train))\n","ffnn_hidden_dim = 256\n","\n","\n","model = TransformerEncoder(acoustic_dim, paralinguistic_dim, linguistic_dim, hidden_dim, num_classes, ffnn_hidden_dim)\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)  # Define the optimizer with learning rate\n","\n","# Convert to PyTorch tensors\n","X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n","X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n","y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n","y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n","\n","# Data Loader\n","train_data = TensorDataset(X_train_tensor, y_train_tensor)\n","train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n","test_data = TensorDataset(X_test_tensor, y_test_tensor)\n","test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n","\n","# Training Loop\n","num_epochs = 100\n","for epoch in range(num_epochs):\n","    model.train()\n","    total_loss = 0\n","    for inputs, labels in train_loader:\n","        # Splitting the input tensor into three feature sets\n","        acoustic_features = inputs[:, :acoustic_end]\n","        paralinguistic_features = inputs[:, acoustic_end:paralinguistic_end]\n","        linguistic_features = inputs[:, paralinguistic_end:]\n","\n","        optimizer.zero_grad()\n","        outputs = model(acoustic_features, paralinguistic_features, linguistic_features)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","        total_loss += loss.item()\n","\n","    average_loss = total_loss / len(train_loader)\n","    print(f'Epoch {epoch+1}/{num_epochs}, Average Loss: {average_loss:.4f}')\n","\n","# Evaluation Function\n","def evaluate_model(model, test_loader):\n","    model.eval()\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for inputs, labels in test_loader:\n","            # Splitting the input tensor into three feature sets\n","            acoustic_features = inputs[:, :acoustic_end]\n","            paralinguistic_features = inputs[:, acoustic_end:paralinguistic_end]\n","            linguistic_features = inputs[:, paralinguistic_end:]\n","\n","            outputs = model(acoustic_features, paralinguistic_features, linguistic_features)\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","    accuracy = 100 * correct / total\n","    return accuracy\n","\n","# Evaluate the model on the test set\n","accuracy = evaluate_model(model, test_loader)\n","print(f'Accuracy on Test Data: {accuracy:.2f}%')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":425},"id":"7GC9zxETo5xe","executionInfo":{"status":"error","timestamp":1705464959994,"user_tz":-330,"elapsed":508,"user":{"displayName":"girish girish","userId":"16813817461950920468"}},"outputId":"55ed9859-2d09-4201-89ec-e1a20f8ac541"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Batch input shape: torch.Size([32, 1800])\n","Batch labels shape: torch.Size([32])\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"mat1 and mat2 shapes cannot be multiplied (32x8 and 6x128)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-82f98940fccd>\u001b[0m in \u001b[0;36m<cell line: 108>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macoustic_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparalinguistic_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinguistic_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-5-82f98940fccd>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, acoustic_features, paralinguistic_features, linguistic_features)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0macoustic_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macoustic_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macoustic_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mparalinguistic_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparalinguistic_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparalinguistic_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mlinguistic_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinguistic_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinguistic_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;31m# Combine the contexts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-5-82f98940fccd>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mattn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mattention_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (32x8 and 6x128)"]}]},{"cell_type":"code","source":["# Load the data\n","acoustic_data = pd.read_csv('/content/drive/MyDrive/Autistic/Autistic_Features/ACOUSTIC.csv')\n","paralinguistic_data = pd.read_csv('/content/drive/MyDrive/Autistic/Autistic_Features/Paralinguistic.csv')\n","linguistic_data = pd.read_csv('/content/drive/MyDrive/Autistic/Autistic_Features/Linguistic_features.csv')\n","\n","# Print the shape of each dataframe\n","print(\"Acoustic Data Shape:\", acoustic_data.shape)\n","print(\"Paralinguistic Data Shape:\", paralinguistic_data.shape)\n","print(\"Linguistic Data Shape:\", linguistic_data.shape)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wvgcm-MLo3bb","executionInfo":{"status":"ok","timestamp":1705432406557,"user_tz":-330,"elapsed":436,"user":{"displayName":"girish girish","userId":"16813817461950920468"}},"outputId":"f32e0fe3-c580-4b00-8db6-f5d8497204a9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Acoustic Data Shape: (213, 770)\n","Paralinguistic Data Shape: (213, 1026)\n","Linguistic Data Shape: (213, 8)\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report\n","from sklearn.preprocessing import StandardScaler\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import TensorDataset, DataLoader\n","\n","# Load the data\n","acoustic_data = pd.read_csv('/content/drive/MyDrive/Autistic/Autistic_Features/ACOUSTIC.csv')\n","paralinguistic_data = pd.read_csv('/content/drive/MyDrive/Autistic/Autistic_Features/Paralinguistic.csv')\n","linguistic_data = pd.read_csv('/content/drive/MyDrive/Autistic/Autistic_Features/Linguistic_features.csv')\n","\n","# Concatinate datasets on 'name'\n","merged_data = acoustic_data.merge(paralinguistic_data, on='name').merge(linguistic_data, on='name')\n","\n","# Preprocess data\n","X = merged_data.drop(columns=['name', 'Class']).values\n","y = merged_data['Class'].values\n","\n","# Standardize and normalize the features\n","scaler = StandardScaler()\n","X = scaler.fit_transform(X)\n","\n","# Split data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Transformer Model\n","class TransformerEncoder(nn.Module):\n","    def __init__(self, input_dim, num_heads, hidden_dim, num_layers, num_classes, ffnn_hidden_dim, dropout_rate):\n","        super(TransformerEncoder, self).__init__()\n","        self.embedding = nn.Linear(input_dim, hidden_dim)\n","        encoder_layers = nn.TransformerEncoderLayer(d_model=hidden_dim, nhead=num_heads, dropout=dropout_rate, batch_first=True)\n","        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers=num_layers)\n","\n","        # Feedforward layer\n","        self.ffnn = nn.Linear(hidden_dim, ffnn_hidden_dim)\n","        self.relu = nn.ReLU()\n","        self.dropout = nn.Dropout(dropout_rate)\n","\n","        # Final classification layer\n","        self.fc = nn.Linear(ffnn_hidden_dim, num_classes)\n","\n","    def forward(self, src):\n","        src = self.embedding(src)\n","        out = self.transformer_encoder(src)\n","        out = self.ffnn(out)\n","        out = self.relu(out)\n","        out = self.dropout(out)\n","        out = self.fc(out)\n","        return out\n","\n","# Model Configuration\n","input_dim = X_train.shape[1]\n","hidden_dim = 128\n","num_heads = 4\n","num_layers = 2\n","num_classes = len(set(y_train))\n","ffnn_hidden_dim = 256\n","dropout_rate = 0.1\n","\n","model = TransformerEncoder(input_dim, num_heads, hidden_dim, num_layers, num_classes, ffnn_hidden_dim, dropout_rate)\n","\n","# Loss, Optimizer and Scheduler\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.AdamW(model.parameters(), lr=0.001)\n","scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n","\n","# Data Loaders\n","train_data = TensorDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.long))\n","train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n","test_data = TensorDataset(torch.tensor(X_test, dtype=torch.float32), torch.tensor(y_test, dtype=torch.long))\n","test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n","\n"],"metadata":{"id":"kkhZrVWLmHof","executionInfo":{"status":"ok","timestamp":1705464996248,"user_tz":-330,"elapsed":428,"user":{"displayName":"girish girish","userId":"16813817461950920468"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# Function to Evaluate the Model\n","def evaluate_model(model, test_loader):\n","    model.eval()\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for inputs, labels in test_loader:\n","            outputs = model(inputs)\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","        return 100 * correct / total\n","\n","# Training Loop\n","num_epochs = 100\n","for epoch in range(num_epochs):\n","    model.train()\n","    total_loss = 0\n","    for inputs, labels in train_loader:\n","        optimizer.zero_grad()  # Zero the gradient buffers\n","        outputs = model(inputs)  # Forward pass\n","        loss = criterion(outputs, labels)  # Compute loss\n","        loss.backward()  # Backpropagation\n","        optimizer.step()  # Update weights\n","        total_loss += loss.item()\n","\n","    scheduler.step()  # Adjust the learning rate\n","    average_loss = total_loss / len(train_loader)\n","    print(f'Epoch {epoch+1}/{num_epochs}, Average Loss: {average_loss:.4f}')\n","\n","    # Optional: Print validation accuracy every epoch\n","    validation_accuracy = evaluate_model(model, test_loader)\n","    print(f'Epoch {epoch+1}/{num_epochs}, Validation Accuracy: {validation_accuracy:.2f}%')\n","\n","# Evaluate the model on the test set\n","accuracy = evaluate_model(model, test_loader)\n","print(f'Accuracy on Test Data: {accuracy:.2f}%')\n","\n","# Calculate and print the classification report\n","true_labels = y_test  # True labels from the test set\n","predicted_labels = []\n","\n","model.eval()\n","with torch.no_grad():\n","    for inputs, labels in test_loader:\n","        outputs = model(inputs)\n","        _, predicted = torch.max(outputs.data, 1)\n","        predicted_labels.extend(predicted.cpu().numpy())\n","\n","classification_rep = classification_report(true_labels, predicted_labels)\n","print(\"Classification Report:\\n\", classification_rep)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sFaOFJCSmWh0","executionInfo":{"status":"ok","timestamp":1705465017071,"user_tz":-330,"elapsed":17663,"user":{"displayName":"girish girish","userId":"16813817461950920468"}},"outputId":"cdc9e991-45d8-411c-8b95-105ebfadf6ef"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100, Average Loss: 0.2252\n","Epoch 1/100, Validation Accuracy: 100.00%\n","Epoch 2/100, Average Loss: 0.0274\n","Epoch 2/100, Validation Accuracy: 81.40%\n","Epoch 3/100, Average Loss: 0.0337\n","Epoch 3/100, Validation Accuracy: 97.67%\n","Epoch 4/100, Average Loss: 0.1026\n","Epoch 4/100, Validation Accuracy: 95.35%\n","Epoch 5/100, Average Loss: 0.1020\n","Epoch 5/100, Validation Accuracy: 97.67%\n","Epoch 6/100, Average Loss: 0.0110\n","Epoch 6/100, Validation Accuracy: 97.67%\n","Epoch 7/100, Average Loss: 0.0087\n","Epoch 7/100, Validation Accuracy: 97.67%\n","Epoch 8/100, Average Loss: 0.0021\n","Epoch 8/100, Validation Accuracy: 97.67%\n","Epoch 9/100, Average Loss: 0.0006\n","Epoch 9/100, Validation Accuracy: 97.67%\n","Epoch 10/100, Average Loss: 0.0003\n","Epoch 10/100, Validation Accuracy: 97.67%\n","Epoch 11/100, Average Loss: 0.0086\n","Epoch 11/100, Validation Accuracy: 97.67%\n","Epoch 12/100, Average Loss: 0.0002\n","Epoch 12/100, Validation Accuracy: 97.67%\n","Epoch 13/100, Average Loss: 0.0002\n","Epoch 13/100, Validation Accuracy: 97.67%\n","Epoch 14/100, Average Loss: 0.0003\n","Epoch 14/100, Validation Accuracy: 97.67%\n","Epoch 15/100, Average Loss: 0.0002\n","Epoch 15/100, Validation Accuracy: 97.67%\n","Epoch 16/100, Average Loss: 0.0002\n","Epoch 16/100, Validation Accuracy: 97.67%\n","Epoch 17/100, Average Loss: 0.0002\n","Epoch 17/100, Validation Accuracy: 97.67%\n","Epoch 18/100, Average Loss: 0.0002\n","Epoch 18/100, Validation Accuracy: 97.67%\n","Epoch 19/100, Average Loss: 0.0002\n","Epoch 19/100, Validation Accuracy: 97.67%\n","Epoch 20/100, Average Loss: 0.0002\n","Epoch 20/100, Validation Accuracy: 97.67%\n","Epoch 21/100, Average Loss: 0.0002\n","Epoch 21/100, Validation Accuracy: 97.67%\n","Epoch 22/100, Average Loss: 0.0002\n","Epoch 22/100, Validation Accuracy: 97.67%\n","Epoch 23/100, Average Loss: 0.0002\n","Epoch 23/100, Validation Accuracy: 97.67%\n","Epoch 24/100, Average Loss: 0.0002\n","Epoch 24/100, Validation Accuracy: 97.67%\n","Epoch 25/100, Average Loss: 0.0005\n","Epoch 25/100, Validation Accuracy: 97.67%\n","Epoch 26/100, Average Loss: 0.0003\n","Epoch 26/100, Validation Accuracy: 97.67%\n","Epoch 27/100, Average Loss: 0.0002\n","Epoch 27/100, Validation Accuracy: 97.67%\n","Epoch 28/100, Average Loss: 0.0002\n","Epoch 28/100, Validation Accuracy: 97.67%\n","Epoch 29/100, Average Loss: 0.0003\n","Epoch 29/100, Validation Accuracy: 97.67%\n","Epoch 30/100, Average Loss: 0.0002\n","Epoch 30/100, Validation Accuracy: 97.67%\n","Epoch 31/100, Average Loss: 0.0002\n","Epoch 31/100, Validation Accuracy: 97.67%\n","Epoch 32/100, Average Loss: 0.0002\n","Epoch 32/100, Validation Accuracy: 97.67%\n","Epoch 33/100, Average Loss: 0.0002\n","Epoch 33/100, Validation Accuracy: 97.67%\n","Epoch 34/100, Average Loss: 0.0003\n","Epoch 34/100, Validation Accuracy: 97.67%\n","Epoch 35/100, Average Loss: 0.0002\n","Epoch 35/100, Validation Accuracy: 97.67%\n","Epoch 36/100, Average Loss: 0.0002\n","Epoch 36/100, Validation Accuracy: 97.67%\n","Epoch 37/100, Average Loss: 0.0002\n","Epoch 37/100, Validation Accuracy: 97.67%\n","Epoch 38/100, Average Loss: 0.0002\n","Epoch 38/100, Validation Accuracy: 97.67%\n","Epoch 39/100, Average Loss: 0.0002\n","Epoch 39/100, Validation Accuracy: 97.67%\n","Epoch 40/100, Average Loss: 0.0002\n","Epoch 40/100, Validation Accuracy: 97.67%\n","Epoch 41/100, Average Loss: 0.0002\n","Epoch 41/100, Validation Accuracy: 97.67%\n","Epoch 42/100, Average Loss: 0.0002\n","Epoch 42/100, Validation Accuracy: 97.67%\n","Epoch 43/100, Average Loss: 0.0002\n","Epoch 43/100, Validation Accuracy: 97.67%\n","Epoch 44/100, Average Loss: 0.0002\n","Epoch 44/100, Validation Accuracy: 97.67%\n","Epoch 45/100, Average Loss: 0.0002\n","Epoch 45/100, Validation Accuracy: 97.67%\n","Epoch 46/100, Average Loss: 0.0002\n","Epoch 46/100, Validation Accuracy: 97.67%\n","Epoch 47/100, Average Loss: 0.0002\n","Epoch 47/100, Validation Accuracy: 97.67%\n","Epoch 48/100, Average Loss: 0.0002\n","Epoch 48/100, Validation Accuracy: 97.67%\n","Epoch 49/100, Average Loss: 0.0002\n","Epoch 49/100, Validation Accuracy: 97.67%\n","Epoch 50/100, Average Loss: 0.0002\n","Epoch 50/100, Validation Accuracy: 97.67%\n","Epoch 51/100, Average Loss: 0.0002\n","Epoch 51/100, Validation Accuracy: 97.67%\n","Epoch 52/100, Average Loss: 0.0002\n","Epoch 52/100, Validation Accuracy: 97.67%\n","Epoch 53/100, Average Loss: 0.0002\n","Epoch 53/100, Validation Accuracy: 97.67%\n","Epoch 54/100, Average Loss: 0.0002\n","Epoch 54/100, Validation Accuracy: 97.67%\n","Epoch 55/100, Average Loss: 0.0002\n","Epoch 55/100, Validation Accuracy: 97.67%\n","Epoch 56/100, Average Loss: 0.0002\n","Epoch 56/100, Validation Accuracy: 97.67%\n","Epoch 57/100, Average Loss: 0.0002\n","Epoch 57/100, Validation Accuracy: 97.67%\n","Epoch 58/100, Average Loss: 0.0002\n","Epoch 58/100, Validation Accuracy: 97.67%\n","Epoch 59/100, Average Loss: 0.0002\n","Epoch 59/100, Validation Accuracy: 97.67%\n","Epoch 60/100, Average Loss: 0.0002\n","Epoch 60/100, Validation Accuracy: 97.67%\n","Epoch 61/100, Average Loss: 0.0002\n","Epoch 61/100, Validation Accuracy: 97.67%\n","Epoch 62/100, Average Loss: 0.0002\n","Epoch 62/100, Validation Accuracy: 97.67%\n","Epoch 63/100, Average Loss: 0.0002\n","Epoch 63/100, Validation Accuracy: 97.67%\n","Epoch 64/100, Average Loss: 0.0002\n","Epoch 64/100, Validation Accuracy: 97.67%\n","Epoch 65/100, Average Loss: 0.0002\n","Epoch 65/100, Validation Accuracy: 97.67%\n","Epoch 66/100, Average Loss: 0.0002\n","Epoch 66/100, Validation Accuracy: 97.67%\n","Epoch 67/100, Average Loss: 0.0002\n","Epoch 67/100, Validation Accuracy: 97.67%\n","Epoch 68/100, Average Loss: 0.0002\n","Epoch 68/100, Validation Accuracy: 97.67%\n","Epoch 69/100, Average Loss: 0.0002\n","Epoch 69/100, Validation Accuracy: 97.67%\n","Epoch 70/100, Average Loss: 0.0002\n","Epoch 70/100, Validation Accuracy: 97.67%\n","Epoch 71/100, Average Loss: 0.0004\n","Epoch 71/100, Validation Accuracy: 97.67%\n","Epoch 72/100, Average Loss: 0.0002\n","Epoch 72/100, Validation Accuracy: 97.67%\n","Epoch 73/100, Average Loss: 0.0002\n","Epoch 73/100, Validation Accuracy: 97.67%\n","Epoch 74/100, Average Loss: 0.0002\n","Epoch 74/100, Validation Accuracy: 97.67%\n","Epoch 75/100, Average Loss: 0.0002\n","Epoch 75/100, Validation Accuracy: 97.67%\n","Epoch 76/100, Average Loss: 0.0002\n","Epoch 76/100, Validation Accuracy: 97.67%\n","Epoch 77/100, Average Loss: 0.0003\n","Epoch 77/100, Validation Accuracy: 97.67%\n","Epoch 78/100, Average Loss: 0.0002\n","Epoch 78/100, Validation Accuracy: 97.67%\n","Epoch 79/100, Average Loss: 0.0002\n","Epoch 79/100, Validation Accuracy: 97.67%\n","Epoch 80/100, Average Loss: 0.0002\n","Epoch 80/100, Validation Accuracy: 97.67%\n","Epoch 81/100, Average Loss: 0.0002\n","Epoch 81/100, Validation Accuracy: 97.67%\n","Epoch 82/100, Average Loss: 0.0002\n","Epoch 82/100, Validation Accuracy: 97.67%\n","Epoch 83/100, Average Loss: 0.0002\n","Epoch 83/100, Validation Accuracy: 97.67%\n","Epoch 84/100, Average Loss: 0.0002\n","Epoch 84/100, Validation Accuracy: 97.67%\n","Epoch 85/100, Average Loss: 0.0002\n","Epoch 85/100, Validation Accuracy: 97.67%\n","Epoch 86/100, Average Loss: 0.0002\n","Epoch 86/100, Validation Accuracy: 97.67%\n","Epoch 87/100, Average Loss: 0.0002\n","Epoch 87/100, Validation Accuracy: 97.67%\n","Epoch 88/100, Average Loss: 0.0002\n","Epoch 88/100, Validation Accuracy: 97.67%\n","Epoch 89/100, Average Loss: 0.0002\n","Epoch 89/100, Validation Accuracy: 97.67%\n","Epoch 90/100, Average Loss: 0.0002\n","Epoch 90/100, Validation Accuracy: 97.67%\n","Epoch 91/100, Average Loss: 0.0002\n","Epoch 91/100, Validation Accuracy: 97.67%\n","Epoch 92/100, Average Loss: 0.0002\n","Epoch 92/100, Validation Accuracy: 97.67%\n","Epoch 93/100, Average Loss: 0.0002\n","Epoch 93/100, Validation Accuracy: 97.67%\n","Epoch 94/100, Average Loss: 0.0002\n","Epoch 94/100, Validation Accuracy: 97.67%\n","Epoch 95/100, Average Loss: 0.0002\n","Epoch 95/100, Validation Accuracy: 97.67%\n","Epoch 96/100, Average Loss: 0.0002\n","Epoch 96/100, Validation Accuracy: 97.67%\n","Epoch 97/100, Average Loss: 0.0002\n","Epoch 97/100, Validation Accuracy: 97.67%\n","Epoch 98/100, Average Loss: 0.0002\n","Epoch 98/100, Validation Accuracy: 97.67%\n","Epoch 99/100, Average Loss: 0.0002\n","Epoch 99/100, Validation Accuracy: 97.67%\n","Epoch 100/100, Average Loss: 0.0002\n","Epoch 100/100, Validation Accuracy: 97.67%\n","Accuracy on Test Data: 97.67%\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","           0       1.00      0.94      0.97        17\n","           1       0.96      1.00      0.98        26\n","\n","    accuracy                           0.98        43\n","   macro avg       0.98      0.97      0.98        43\n","weighted avg       0.98      0.98      0.98        43\n","\n"]}]}]}