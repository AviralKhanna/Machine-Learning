{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":653195,"sourceType":"datasetVersion","datasetId":325566}],"dockerImageVersionId":30408,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# librosa is a Python library for analyzing audio and music. \n# It can be used to extract the data from the audio files we will see it later\nimport librosa \nimport torch\nimport librosa.display\nimport warnings\nwarnings.filterwarnings(\"ignore\") \n# to play the audio files\nfrom IPython.display import Audio\nplt.style.use('seaborn-white')","metadata":{"execution":{"iopub.status.busy":"2023-03-07T18:31:24.151949Z","iopub.execute_input":"2023-03-07T18:31:24.152397Z","iopub.status.idle":"2023-03-07T18:31:27.698590Z","shell.execute_reply.started":"2023-03-07T18:31:24.152362Z","shell.execute_reply":"2023-03-07T18:31:27.697499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Extractor with x-vector","metadata":{}},{"cell_type":"code","source":"# Reference; https://huggingface.co/speechbrain/spkrec-xvect-voxceleb\n! pip install speechbrain","metadata":{"execution":{"iopub.status.busy":"2023-03-07T18:31:27.704539Z","iopub.execute_input":"2023-03-07T18:31:27.707228Z","iopub.status.idle":"2023-03-07T18:31:40.126852Z","shell.execute_reply.started":"2023-03-07T18:31:27.707183Z","shell.execute_reply":"2023-03-07T18:31:40.125640Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# audio file is decoded on the fly\nimport torchaudio\nfrom speechbrain.pretrained import EncoderClassifier\nclassifier = EncoderClassifier.from_hparams(source=\"speechbrain/spkrec-xvect-voxceleb\", savedir=\"pretrained_models/spkrec-xvect-voxceleb\")\n\ndef extract_features(path):\n    signal, fs =torchaudio.load(path)\n    embeddings = classifier.encode_batch(signal)\n    return np.array(embeddings.mean(axis = 0).squeeze())","metadata":{"execution":{"iopub.status.busy":"2023-03-07T18:31:40.128980Z","iopub.execute_input":"2023-03-07T18:31:40.129398Z","iopub.status.idle":"2023-03-07T18:31:44.955292Z","shell.execute_reply.started":"2023-03-07T18:31:40.129356Z","shell.execute_reply":"2023-03-07T18:31:44.954219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CREMA-D","metadata":{}},{"cell_type":"code","source":"crema = \"/kaggle/input/cremad/AudioWAV/\"\ncrema_directory_list = os.listdir(crema)\nfile_name = []\nfile_emotion = []\nfile_path = []\n\nfor file in crema_directory_list:\n    # storing file paths\n    file_name.append(file.split('.')[0])\n    file_path.append(crema + file)\n    # storing file emotions\n    part=file.split('_')\n    if part[2] == 'SAD':\n        file_emotion.append('Sadness')\n    elif part[2] == 'ANG':\n        file_emotion.append('Anger')\n    elif part[2] == 'DIS':\n        file_emotion.append('Disgust')\n    elif part[2] == 'FEA':\n        file_emotion.append('Fear')\n    elif part[2] == 'HAP':\n        file_emotion.append('Happiness')\n    elif part[2] == 'NEU':\n        file_emotion.append('Neutral')\n    else:\n        file_emotion.append('Unknown')\n\n        \nfilename_df = pd.DataFrame(file_name, columns=['Name'])\npath_df = pd.DataFrame(file_path, columns=['Path'])\nemotion_df = pd.DataFrame(file_emotion, columns=['Emotions'])\nCrema_df = pd.concat([filename_df,path_df, emotion_df], axis=1)\nCrema_df['source'] = 'cremad'\ncdataset = Crema_df\ncemotions = ['Sadness', 'Happiness', 'Anger', 'Fear', 'Neutral', 'Disgust']\ncdataset = cdataset[cdataset['Emotions'].isin(cemotions)].reset_index(drop = True)\n#cdataset['Emotions'].value_counts()\ncdataset['Emotions'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-03-07T18:31:44.958588Z","iopub.execute_input":"2023-03-07T18:31:44.958999Z","iopub.status.idle":"2023-03-07T18:31:45.226260Z","shell.execute_reply.started":"2023-03-07T18:31:44.958957Z","shell.execute_reply":"2023-03-07T18:31:45.225161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn import preprocessing\nlec = preprocessing.LabelEncoder()\ncdataset['labels'] = lec.fit_transform(cdataset['Emotions'])\nlec_name_mapping = dict(zip(lec.classes_, lec.transform(lec.classes_)))\nprint(lec_name_mapping)","metadata":{"execution":{"iopub.status.busy":"2023-03-07T18:31:45.227711Z","iopub.execute_input":"2023-03-07T18:31:45.228293Z","iopub.status.idle":"2023-03-07T18:31:45.278970Z","shell.execute_reply.started":"2023-03-07T18:31:45.228237Z","shell.execute_reply":"2023-03-07T18:31:45.277894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cdataset.head()","metadata":{"execution":{"iopub.status.busy":"2023-03-07T18:31:45.280531Z","iopub.execute_input":"2023-03-07T18:31:45.280899Z","iopub.status.idle":"2023-03-07T18:31:45.295681Z","shell.execute_reply.started":"2023-03-07T18:31:45.280862Z","shell.execute_reply":"2023-03-07T18:31:45.294621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feats = np.array(extract_features(cdataset['Path'][0]))\nfeats.shape","metadata":{"execution":{"iopub.status.busy":"2023-03-07T18:31:45.297258Z","iopub.execute_input":"2023-03-07T18:31:45.297634Z","iopub.status.idle":"2023-03-07T18:31:45.418251Z","shell.execute_reply.started":"2023-03-07T18:31:45.297598Z","shell.execute_reply":"2023-03-07T18:31:45.417153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"waveform_embeddings = []\nfor i in range(len(cdataset)):\n    features = extract_features(cdataset['Path'][i])\n    waveform_embeddings.append(features)\n\nwaveform_embeddings = np.array(waveform_embeddings)\nprint(waveform_embeddings.shape)","metadata":{"execution":{"iopub.status.busy":"2023-03-07T18:31:45.419812Z","iopub.execute_input":"2023-03-07T18:31:45.420254Z","iopub.status.idle":"2023-03-07T18:35:40.499381Z","shell.execute_reply.started":"2023-03-07T18:31:45.420217Z","shell.execute_reply":"2023-03-07T18:35:40.498267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Reference t-SNE: https://www.kaggle.com/code/colinmorris/visualizing-embeddings-with-t-sne\nfrom sklearn.manifold import TSNE\n\n# The default of 1,000 iterations gives fine results, but I'm training for longer just to eke\n# out some marginal improvements. NB: This takes almost an hour!\ntsne = TSNE(random_state=1, n_iter=1000, metric=\"cosine\")\n\ntsne_proj = tsne.fit_transform(waveform_embeddings)\n# Plot those points as a scatter plot and label them based on the pred labels\nfrom matplotlib import cm\ncmap = cm.get_cmap('tab20')\nfig, ax = plt.subplots(figsize=(8,8))\nnum_categories = 6\n# {'Anger': 0, 'Disgust': 1, 'Fear': 2, 'Happiness': 3, 'Neutral': 4, 'Sadness': 5}\nlabels = ['Anger', 'Disgust', 'Fear', 'Happiness', 'Neutral', 'Sadness']\nfor lab in range(num_categories):\n    indices = cdataset['labels']==lab\n    ax.scatter(tsne_proj[indices,0],tsne_proj[indices,1], c=np.array(cmap(lab)).reshape(1,4), label = labels[lab] ,alpha=0.5)\nax.legend(fontsize='large', markerscale=2)\nplt.savefig(\"./xvector_cremad_tsne\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-03-07T18:38:01.633450Z","iopub.execute_input":"2023-03-07T18:38:01.634177Z","iopub.status.idle":"2023-03-07T18:39:04.005789Z","shell.execute_reply.started":"2023-03-07T18:38:01.634138Z","shell.execute_reply":"2023-03-07T18:39:04.004699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"waveform_embeddings1 = np.expand_dims(waveform_embeddings, -1)\nprint(waveform_embeddings1.shape)\n\"\"\"\nwaveform_embeddings1 = waveform_embeddings1.reshape(7442, 1, 512)\nprint(waveform_embeddings1.shape)\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2023-03-07T18:35:40.503510Z","iopub.execute_input":"2023-03-07T18:35:40.506006Z","iopub.status.idle":"2023-03-07T18:35:40.521190Z","shell.execute_reply.started":"2023-03-07T18:35:40.505967Z","shell.execute_reply":"2023-03-07T18:35:40.519874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training and Test Data Split","metadata":{}},{"cell_type":"markdown","source":"Refrence for k-fold: https://medium.com/towards-artificial-intelligence/importance-of-k-fold-cross-validation-in-machine-learning-a0d76f49493e\n\nThe general procedure for k-fold cross-validation is as follows:\n\n1. Shuffle the dataset randomly\n\n2. Split the dataset into k groups\n\n3. For each unique group:\n\n\n3(i). Take the group as a holdout or test data set\n\n3(ii). Take the remaining groups as a training data set\n\n3(iii). Fit a model on the training set and evaluate it on the test set\n\n\n3(iv). Retain the evaluation score and discard the model\n\n\n3(v). Summarize the skill of the model using the sample of model evaluation scores \n\n\nN.B: The test set in each fold does not overlap with each other.\n\n","metadata":{}},{"cell_type":"code","source":"# Train and test split for Speaker Recognition Embeddings\n\nseed = 0\n# wav2clip CREMA-D\n# Train and test split\nfrom sklearn.model_selection import train_test_split, cross_val_predict\nx_train, x_test, y_train, y_test = train_test_split(waveform_embeddings1, cdataset['labels'], test_size = 0.2, random_state = seed)\nprint(x_train.shape)\nprint(x_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)\n\nx = np.concatenate([x_train, x_test], axis = 0)\ny = np.concatenate([y_train, y_test], axis = 0)\n\"\"\"\n# Fold 1\nx_train, x_test = x[:5953], x[5953:]\ny_train, y_test = y[:5953], y[5953:]\nprint(x_train.shape)\nprint(x_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)\n\n# Fold 2\nx_train, x_test = np.concatenate([x[:4465], x[5953:]], axis = 0), x[4465:5953]\ny_train, y_test = np.concatenate([y[:4465], y[5953:]], axis = 0), y[4465:5953]\nprint(x_train.shape)\nprint(x_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)\n\n# Fold 3\nx_train, x_test = np.concatenate([x[:2977], x[4465:]], axis = 0), x[2977:4465]\ny_train, y_test = np.concatenate([y[:2977], y[4465:]], axis = 0), y[2977:4465]\nprint(x_train.shape)\nprint(x_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)\n\n# Fold 4\nx_train, x_test = np.concatenate([x[:1489], x[2977:]], axis = 0), x[1489:2977]\ny_train, y_test = np.concatenate([y[:1489], y[2977:]], axis = 0), y[1489:2977]\nprint(x_train.shape)\nprint(x_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)\n\"\"\"\n# Fold 5\nx_train, x_test = x[1489:], x[:1489]\ny_train, y_test = y[1489:], y[:1489]\nprint(x_train.shape)\nprint(x_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)\n","metadata":{"execution":{"iopub.status.busy":"2023-03-07T18:45:55.072364Z","iopub.execute_input":"2023-03-07T18:45:55.073609Z","iopub.status.idle":"2023-03-07T18:45:55.098722Z","shell.execute_reply.started":"2023-03-07T18:45:55.073557Z","shell.execute_reply":"2023-03-07T18:45:55.097354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CNN LSTM-Attention","metadata":{}},{"cell_type":"code","source":"#! pip install attention","metadata":{"execution":{"iopub.status.busy":"2023-03-07T18:45:55.101144Z","iopub.execute_input":"2023-03-07T18:45:55.101681Z","iopub.status.idle":"2023-03-07T18:45:55.107711Z","shell.execute_reply.started":"2023-03-07T18:45:55.101640Z","shell.execute_reply":"2023-03-07T18:45:55.106440Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#from attention import Attention","metadata":{"execution":{"iopub.status.busy":"2023-03-07T18:45:55.109421Z","iopub.execute_input":"2023-03-07T18:45:55.109924Z","iopub.status.idle":"2023-03-07T18:45:55.117142Z","shell.execute_reply.started":"2023-03-07T18:45:55.109859Z","shell.execute_reply":"2023-03-07T18:45:55.115683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pickle\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom time import time\nimport tensorflow as tf\nimport keras\nfrom keras.preprocessing.sequence import TimeseriesGenerator\nfrom scipy import stats\nfrom IPython.display import display, HTML\n\nfrom sklearn import metrics\nfrom sklearn.metrics import classification_report\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\n\nimport keras\nfrom keras import optimizers\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Reshape\nfrom keras.layers import Conv3D,Conv2D, MaxPooling2D,TimeDistributed,LSTM,ConvLSTM2D\nfrom keras.utils import np_utils\n\nfrom tensorflow.keras.layers import Input, Lambda, Dense, Flatten,Conv2D\nfrom tensorflow.keras.applications.resnet50 import preprocess_input\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\nfrom tensorflow.keras import datasets, layers, models\nfrom tensorflow.keras.models import Sequential\nimport numpy as np\nfrom glob import glob\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.layers import MaxPooling2D\nimport keras\nfrom keras.layers import Input, Conv2D, Dense, concatenate, Embedding, GlobalAveragePooling1D\nfrom keras.models import Model","metadata":{"execution":{"iopub.status.busy":"2023-03-07T18:45:55.118916Z","iopub.execute_input":"2023-03-07T18:45:55.119435Z","iopub.status.idle":"2023-03-07T18:45:55.130872Z","shell.execute_reply.started":"2023-03-07T18:45:55.119400Z","shell.execute_reply":"2023-03-07T18:45:55.129669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# LSTM + Attention\n\n\"\"\"\nip = Input((512,1))\nlstm1 = tf.keras.layers.LSTM(30, return_sequences=False, activation=tf.nn.relu)(ip)\n#lstm2 = tf.keras.layers.LSTM(20, return_sequences=True, activation=tf.nn.relu)(lstm1)\n#attention = Attention(5)(lstm1)\ndense1 = keras.layers.Dense(30, activation='relu')(lstm1)\noutput = keras.layers.Dense(6, activation='softmax')(dense1)\nmodel = Model(inputs=ip, outputs=output)\nmodel.summary()  \n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2023-03-07T18:45:55.134139Z","iopub.execute_input":"2023-03-07T18:45:55.134745Z","iopub.status.idle":"2023-03-07T18:45:55.144082Z","shell.execute_reply.started":"2023-03-07T18:45:55.134708Z","shell.execute_reply":"2023-03-07T18:45:55.142832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#! pip install keras_nlp","metadata":{"execution":{"iopub.status.busy":"2023-03-07T18:45:55.145891Z","iopub.execute_input":"2023-03-07T18:45:55.146317Z","iopub.status.idle":"2023-03-07T18:45:55.151792Z","shell.execute_reply.started":"2023-03-07T18:45:55.146257Z","shell.execute_reply":"2023-03-07T18:45:55.150617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# CNN + Attention\nfrom keras.layers import Input, Conv2D, Dense, concatenate, Embedding, GlobalAveragePooling1D, Attention\n#import keras_nlp\n\n\ndef create_model():\n    \n    # embeddings from xvector\n    input_speakrec = keras.Input(shape=[512, 1])\n    x1 = tf.keras.layers.Conv1D(32, 3, activation = 'relu', padding = 'same')(input_speakrec)\n    x1 = tf.keras.layers.MaxPooling1D()(x1)\n    #x1 = tf.keras.layers.Conv1D(64, 3, activation = 'relu', padding = 'same')(x1)\n    #x1 = tf.keras.layers.MaxPooling1D()(x1)\n    #x = tf.keras.layers.Attention()([x, x])\n    x1 = tf.keras.layers.Flatten()(x1)\n    \n    \"\"\"\n    # MFCC\n    input_mfcc = keras.Input(shape=[40, 1])\n    x2 = tf.keras.layers.Conv1D(32, 3, activation = 'relu', padding = 'same')(input_mfcc)\n    x2 = tf.keras.layers.MaxPooling1D()(x2)\n    #x2 = tf.keras.layers.Conv1D(64, 3, activation = 'relu', padding = 'same')(x2)\n    #x2 = tf.keras.layers.MaxPooling1D()(x2)\n    #x = tf.keras.layers.Attention()([x, x])\n    x2 = tf.keras.layers.Flatten()(x2)\n    \"\"\"\n    \n    #oncat = concatenate([x1, x2],axis = 1)\n    #concat = tf.reshape(concat, [concat,1])\n    #x = tf.keras.layers.Dropout(0.2)(x)\n    #x = tf.keras.layers.Dropout(0.2)(x)\n    #x = tf.keras.layers.BatchNormalization()(x)\n    #concat = tf.keras.layers.Reshape((1, 8832))(concat)\n    \n    #encoder = keras_nlp.layers.TransformerEncoder(intermediate_dim=64, num_heads=4)\n    #x = encoder(concat)\n    #x = tf.keras.layers.GlobalAveragePooling1D()(x)\n\n    #x = tf.keras.layers.Reshape((1, 8832))(x)\n    x = tf.keras.layers.Dense(200, activation='relu')(x1)\n    x = tf.keras.layers.BatchNormalization()(x)\n    #x = tf.keras.layers.Dense(224, activation = 'relu')(x)\n    #x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.Dense(90, activation = 'relu')(x)\n    x = tf.keras.layers.Dropout(0.2)(x)\n    x = tf.keras.layers.Dense(56, activation = 'relu')(x)\n    output = tf.keras.layers.Dense(6, activation='softmax')(x)\n    model = keras.Model(inputs= input_speakrec, outputs=output)\n    return model\n\nmodel = create_model()\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-03-07T18:45:55.153442Z","iopub.execute_input":"2023-03-07T18:45:55.154424Z","iopub.status.idle":"2023-03-07T18:45:55.267617Z","shell.execute_reply.started":"2023-03-07T18:45:55.154385Z","shell.execute_reply":"2023-03-07T18:45:55.266841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#! pip install --upgrade keras-nlp","metadata":{"execution":{"iopub.status.busy":"2023-03-07T18:45:55.268616Z","iopub.execute_input":"2023-03-07T18:45:55.268933Z","iopub.status.idle":"2023-03-07T18:45:55.273384Z","shell.execute_reply.started":"2023-03-07T18:45:55.268899Z","shell.execute_reply":"2023-03-07T18:45:55.272585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Reference: Transformer Encoder (https://keras.io/api/keras_nlp/layers/transformer_encoder/)\n\"\"\"\nimport keras_nlp\nfrom tensorflow import keras\n\n\ndef transformer_model():\n # Create a single transformer encoder layer.\n  encoder = keras_nlp.layers.TransformerEncoder(intermediate_dim=120, num_heads=8)\n  # Create a simple model containing the encoder.\n  input = keras.Input(shape=[1, 512])\n  x = encoder(input)\n  x = tf.keras.layers.GlobalAveragePooling1D()(x)\n  x = tf.keras.layers.Dense(300, activation='relu')(x)\n  x = tf.keras.layers.BatchNormalization()(x)\n  tf.keras.layers.Dropout(0.2),\n  tf.keras.layers.Dense(224, activation = 'relu'),\n  tf.keras.layers.BatchNormalization(),\n  tf.keras.layers.Dense(128, activation = 'relu'),\n  x = tf.keras.layers.Dropout(0.2)(x)\n  x =  tf.keras.layers.Dense(36, activation = 'relu')(x)\n  output = tf.keras.layers.Dense(6, activation='softmax')(x)\n  model = keras.Model(inputs=input, outputs=output)\n  return model\n\n\n# Call encoder on the inputs.\ninput_data = tf.random.uniform(shape=[10, 1, 512])\noutput = model(input_data)\nprint(output.shape)\n\nmodel = transformer_model()\nmodel.summary()\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2023-03-07T18:45:55.324165Z","iopub.execute_input":"2023-03-07T18:45:55.324716Z","iopub.status.idle":"2023-03-07T18:45:55.331562Z","shell.execute_reply.started":"2023-03-07T18:45:55.324688Z","shell.execute_reply":"2023-03-07T18:45:55.330684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lr = 1e-3\nimport tensorflow_addons as tfa\noptimizer = tfa.optimizers.RectifiedAdam(learning_rate= lr)\n#optimizer = tf.keras.optimizers.Adam(learning_rate= lr)\n# Compile the model with the Riemannian optimizer            \nmodel.compile(\n    optimizer=optimizer,\n    loss=tf.keras.losses.SparseCategoricalCrossentropy(),  #from_logits=True\n    metrics= ['accuracy']  #[tf.keras.metrics.SparseCategoricalAccuracy()],\n)\n\n\nreduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor = 'val_accuracy',\n                                                 factor = 0.2,\n                                                 patience = 1,\n                                                 verbose = 1,\n                                                 min_delta = 1e-4,\n                                                 min_lr = 1e-15,\n                                                 mode = 'max')\n\nearlystopping = tf.keras.callbacks.EarlyStopping(monitor = 'val_accuracy',\n                                                 min_delta = 1e-4,\n                                                 patience = 70,\n                                                 mode = 'max',\n                                                 restore_best_weights = True,\n                                                 verbose = 1)\n\ncheckpointer = tf.keras.callbacks.ModelCheckpoint(filepath = './cnn_cremad.hdf5',\n                                                  monitor = 'val_accuracy', \n                                                  verbose = 1, \n                                                  save_best_only = True,\n                                                  save_weights_only = True,\n                                                  mode = 'max')\n\ncallbacks = [earlystopping, checkpointer, reduce_lr]#reduce_lr]","metadata":{"execution":{"iopub.status.busy":"2023-03-07T18:45:55.333347Z","iopub.execute_input":"2023-03-07T18:45:55.333742Z","iopub.status.idle":"2023-03-07T18:45:55.350317Z","shell.execute_reply.started":"2023-03-07T18:45:55.333704Z","shell.execute_reply":"2023-03-07T18:45:55.348604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import time\nstart_time = time.time()\nhistory = model.fit( x_train, y_train,\n                   validation_data =  (x_test, y_test),\n                   batch_size = 32,\n                   epochs = 50,\n                   callbacks = callbacks)\n\nprint(\"--- %s seconds ---\" % (time.time() - start_time))","metadata":{"execution":{"iopub.status.busy":"2023-03-07T18:45:55.353605Z","iopub.execute_input":"2023-03-07T18:45:55.353869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model.predict(x_test)\nprint(y_pred.shape)\ny_predmax = tf.math.argmax(y_pred, axis = 1)\nfrom sklearn.metrics import classification_report\ncr = classification_report(y_test, y_predmax, digits = 6)\nprint(cr)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the saved model\n\"\"\"\ndef load_trained_model(weights_path):\n   model = create_model()\n   model.load_weights(weights_path)\n   return model\n\nnew_model = load_trained_model('./cnn_cremad.hdf5')\nnew_model.summary()\ny_predmax = tf.math.argmax(y_pred, axis = 1)\nfrom sklearn.metrics import classification_report\ncr = classification_report(y_test, y_predmax, digits = 6)\nprint(cr)\ny_predmax = tf.math.argmax(y_pred, axis = 1)\nfrom sklearn.metrics import classification_report\ncr = classification_report(y_test, y_predmax, digits = 6)\nprint(cr)\n\"\"\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}