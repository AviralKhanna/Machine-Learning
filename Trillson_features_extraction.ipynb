{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "-6-yoERCI2Rh",
        "outputId": "f55d7bb6-8a4c-4495-cce5-5b1238a1d450"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Mountpoint must not already contain files",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-d5df0069828e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    187\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Mountpoint must not be a symlink'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Mountpoint must not already contain files'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Mountpoint must either be a directory or not exist'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Mountpoint must not already contain files"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***LIBRARIES***"
      ],
      "metadata": {
        "id": "XZE5ys0MV00d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import torchaudio\n",
        "import pandas as pd\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "kmmpyIDmV21u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow_hub torchaudio pandas"
      ],
      "metadata": {
        "id": "gZ5krGSEWOCO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow_hub"
      ],
      "metadata": {
        "id": "j4JbKcGEWRba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TIRLLSON**"
      ],
      "metadata": {
        "id": "QQykVmiPVKrS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logic"
      ],
      "metadata": {
        "id": "YwcCHTMeaW1z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "10mRUnDeFwYw"
      },
      "outputs": [],
      "source": [
        "# #Trillson Reference: https://tfhub.dev/google/nonsemantic-speech-benchmark/trillsson4/1\n",
        "m = hub.KerasLayer('https://tfhub.dev/google/trillsson4/1')\n",
        "def extract_features(path):\n",
        "    sample_rate = 16000\n",
        "    array, fs = torchaudio.load(path)\n",
        "    array = np.array(array)\n",
        "    # NOTE: Audio should be floats in [-1, 1], sampled at 16kHz. Model input is of\n",
        "    # the shape [batch size, time].\n",
        "    embeddings = m(array)['embedding']\n",
        "    # Models internally aggregate over time. For a time-series of embeddings, the\n",
        "    # user can frame audio however they want.\n",
        "    embeddings.shape.assert_is_compatible_with([None, 1024])\n",
        "    embeddings = np.squeeze(np.array(embeddings), axis = 0)\n",
        "    return embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CSV"
      ],
      "metadata": {
        "id": "j5bAWAzVaaIH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Trillson model from TensorFlow Hub\n",
        "m = hub.KerasLayer('https://tfhub.dev/google/trillsson4/1')\n",
        "\n",
        "# Function to extract features from an audio file\n",
        "def extract_features(path):\n",
        "    sample_rate = 16000\n",
        "    array, fs = torchaudio.load(path)\n",
        "    array = np.array(array)\n",
        "    # NOTE: Audio should be floats in [-1, 1], sampled at 16kHz. Model input is of\n",
        "    # the shape [batch size, time].\n",
        "    embeddings = m(array)['embedding']\n",
        "    # Models internally aggregate over time. For a time-series of embeddings, the\n",
        "    # user can frame audio however they want.\n",
        "    embeddings.shape.assert_is_compatible_with([None, 1024])\n",
        "    embeddings = np.squeeze(np.array(embeddings), axis=0)\n",
        "    return embeddings\n",
        "\n",
        "# Function to save features to a CSV file\n",
        "def save_to_csv(features, output_file):\n",
        "    df = pd.DataFrame(features)\n",
        "    df.to_csv(output_file, index=False)\n",
        "    print(f\"Features saved to {output_file}\")\n",
        "\n",
        "# Example usage\n",
        "input_audio_file = '/content/drive/MyDrive/Autistic/Combined/Abnormal/A001.wav'\n",
        "output_csv_file = 'file.csv'\n",
        "\n",
        "# Extract features from the audio file\n",
        "features = extract_features(input_audio_file)\n",
        "\n",
        "# Save features to a CSV file\n",
        "save_to_csv(features, output_csv_file)\n"
      ],
      "metadata": {
        "id": "yzfNE3jPIWYp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4d1b495-8109-4651-980c-8df350dfaaf4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features saved to file.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ALL features"
      ],
      "metadata": {
        "id": "lM6s-lGXafWF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Trill model from TensorFlow Hub\n",
        "model = hub.load('https://tfhub.dev/google/nonsemantic-speech-benchmark/trill/3')\n",
        "\n",
        "def extract_features(audio_path):\n",
        "    # Load the audio file\n",
        "    audio, sr = librosa.load(audio_path, sr=None)\n",
        "\n",
        "    # Resample the audio to 16kHz\n",
        "    if sr != 16000:\n",
        "        audio = librosa.resample(audio, orig_sr=sr, target_sr=16000)\n",
        "        sr = 16000\n",
        "\n",
        "    # Convert the audio waveform to the format expected by the model\n",
        "    audio = audio[np.newaxis, :]\n",
        "    audio = tf.convert_to_tensor(audio, dtype=tf.float32)\n",
        "\n",
        "    # Extract features\n",
        "    embeddings = model(samples=audio, sample_rate=sr)\n",
        "\n",
        "    # Handle the dictionary output\n",
        "    # Replace 'embedding' with the correct key if different\n",
        "    embedding_key = 'embedding' if 'embedding' in embeddings else list(embeddings.keys())[0]\n",
        "    return embeddings[embedding_key].numpy()\n",
        "\n",
        "# Example usage\n",
        "audio_path = '/content/drive/MyDrive/Autistic/Combined/Abnormal/A001.wav'  # Replace with your audio file path\n",
        "features = extract_features(audio_path)\n",
        "\n",
        "# Save the features to a CSV file\n",
        "csv_file = 'extracted_features.csv'  # Output CSV file name\n",
        "\n",
        "# Flatten the features array for CSV writing\n",
        "flattened_features = features.flatten()\n",
        "\n",
        "with open(csv_file, mode='w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow(flattened_features)\n",
        "\n",
        "print(f\"Features saved to {csv_file}\")\n"
      ],
      "metadata": {
        "id": "-fiBCd_rIhSy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1aa123eb-d531-4e49-c641-65c964de147b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features saved to extracted_features.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "FOlder"
      ],
      "metadata": {
        "id": "BjRQQ5Q1aS9l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m = hub.KerasLayer('https://tfhub.dev/google/trillsson4/1')\n",
        "\n",
        "# Function to extract features from an audio file\n",
        "def extract_features(path):\n",
        "    sample_rate = 16000\n",
        "    array, fs = torchaudio.load(path)\n",
        "    array = np.array(array)\n",
        "    # NOTE: Audio should be floats in [-1, 1], sampled at 16kHz. Model input is of\n",
        "    # the shape [batch size, time].\n",
        "    embeddings = m(array)['embedding']\n",
        "    # Models internally aggregate over time. For a time-series of embeddings, the\n",
        "    # user can frame audio however they want.\n",
        "    embemddings.shape.assert_is_compatible_with([None, 1024])\n",
        "    embeddings = np.squeeze(np.array(embeddings), axis=0)\n",
        "    return embeddings\n",
        "\n",
        "# Function to save features to a CSV file\n",
        "def save_to_csv(features, file_names, output_file):\n",
        "    df = pd.DataFrame(features, columns=[f'feature_{i}' for i in range(features.shape[1])])\n",
        "    df['file_name'] = file_names\n",
        "    df.to_csv(output_file, index=False)\n",
        "    print(f\"Features saved to {output_file}\")\n",
        "\n",
        "# Function to process all audio files in a folder\n",
        "def process_folder(input_folder, output_csv_file):\n",
        "    features_list = []\n",
        "    file_names = []\n",
        "\n",
        "    for filename in os.listdir(input_folder):\n",
        "        if filename.endswith(\".wav\"):\n",
        "            file_path = os.path.join(input_folder, filename)\n",
        "            features = extract_features(file_path)\n",
        "            features_list.append(features)\n",
        "            file_names.append(filename)\n",
        "\n",
        "    features_array = np.vstack(features_list)\n",
        "    save_to_csv(features_array, file_names, output_csv_file)\n",
        "\n",
        "# Example usage\n",
        "input_audio_folder = '/content/drive/MyDrive/Autistic/Combined/Abnormal'\n",
        "output_csv_file = 'Abnormal.csv'\n",
        "\n",
        "# Process all audio files in the folder and save features to a CSV file\n",
        "process_folder(input_audio_folder, output_csv_file)\n"
      ],
      "metadata": {
        "id": "NF_P7CzPVUNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#   seprate csv"
      ],
      "metadata": {
        "id": "SYO3X9ganPwn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Trillson model from TensorFlow Hub\n",
        "m = hub.KerasLayer('https://tfhub.dev/google/trillsson4/1')\n",
        "\n",
        "# Function to extract features from an audio file\n",
        "def extract_features(path):\n",
        "    sample_rate = 16000\n",
        "    array, fs = torchaudio.load(path)\n",
        "\n",
        "    # Check if the sampling rate is not 16 kHz\n",
        "    if fs != sample_rate:\n",
        "        # Resample audio to 16 kHz\n",
        "        resampler = torchaudio.transforms.Resample(fs, sample_rate)\n",
        "        array = resampler(array)\n",
        "        print(f\"Resampled audio to {sample_rate} Hz\")\n",
        "\n",
        "    array = np.array(array)\n",
        "\n",
        "    # Ensure the waveform has only one channel (mono)\n",
        "    if array.shape[0] > 1:\n",
        "        array = array.mean(dim=0, keepdim=True)\n",
        "\n",
        "    embeddings = m(array)['embedding']\n",
        "    embeddings.shape.assert_is_compatible_with([None, 1024])\n",
        "\n",
        "    # Squeeze dimensions appropriately\n",
        "    embeddings = np.squeeze(np.array(embeddings), axis=0)\n",
        "\n",
        "    return embeddings\n",
        "\n",
        "# Function to save features to a CSV file\n",
        "def save_to_csv(features, output_file):\n",
        "    df = pd.DataFrame(features)\n",
        "    df.to_csv(output_file, index=False)\n",
        "    print(f\"Features saved to {output_file}\")\n",
        "\n",
        "# Function to process a folder of audio files\n",
        "def process_folder(input_folder, output_folder):\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "    for filename in os.listdir(input_folder):\n",
        "        if filename.endswith('.wav'):\n",
        "            input_audio_file = os.path.join(input_folder, filename)\n",
        "            output_csv_file = os.path.join(output_folder, f\"{os.path.splitext(filename)[0]}.csv\")\n",
        "\n",
        "            # Check if the CSV file already exists for the current audio file\n",
        "            if not os.path.exists(output_csv_file):\n",
        "                features = extract_features(input_audio_file)\n",
        "                save_to_csv(features, output_csv_file)\n",
        "            else:\n",
        "                print(f\"Features already exist for {input_audio_file}. Skipping.\")\n",
        "\n",
        "# Example usage\n",
        "input_folder = '/content/drive/MyDrive/Autistic/Combined/Abnormal'\n",
        "output_folder = '/content/drive/MyDrive/Autistic/Combined/Features_trillson/Abnormal'\n",
        "\n",
        "process_folder(input_folder, output_folder)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "id": "Ag8JPaAxnOaN",
        "outputId": "ff6feaa6-f713-4c71-8426-14bab560898d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/Autistic/Combined/Abnormal'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-dc17aacf0d6d>\u001b[0m in \u001b[0;36m<cell line: 56>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0moutput_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/MyDrive/Autistic/Combined/Features_trillson/Abnormal'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m \u001b[0mprocess_folder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-8-dc17aacf0d6d>\u001b[0m in \u001b[0;36mprocess_folder\u001b[0;34m(input_folder, output_folder)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.wav'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0minput_audio_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Autistic/Combined/Abnormal'"
          ]
        }
      ]
    }
  ]
}